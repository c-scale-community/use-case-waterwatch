{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5c7cd7e-fcc2-471d-be06-b1f6dc8e4d18",
   "metadata": {},
   "source": [
    "# Test add water occurrence\n",
    "\n",
    "The water watch algorithm makes use of the Global Water Occurrence dataset where water presence cannot be detected from the image (clouds, missing data, etc.).\n",
    "Because this data is needed in one datacube, we need to add the water occurrence as a band in one datacube together with the optical data.\n",
    "\n",
    "In this notebook, this process is tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a79d08-4f48-4fdc-abde-e636466986e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from typing import List, Dict, Tuple, Union\n",
    "from pathlib import Path\n",
    "\n",
    "import geojson\n",
    "from openeo import connect, Connection\n",
    "from openeo.rest.datacube import DataCube\n",
    "from pyproj import CRS, Proj, Transformer\n",
    "from pyproj.aoi import AreaOfInterest\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "from shapely.ops import transform\n",
    "\n",
    "from utils import Reservoir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fb096d-e1ce-4061-aef9-9cc73060f40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to backend:\n",
    "openeo_platform_url: str = \"openeo.cloud\"\n",
    "vito_url: str = \"https://openeo.vito.be/openeo/1.0\"\n",
    "vito_dev_url: str = \"https://openeo-dev.vito.be/openeo/1.0\"\n",
    "\n",
    "backend_url = vito_url\n",
    "\n",
    "con: Connection = connect(backend_url)\n",
    "con.authenticate_oidc(provider_id=\"egi\")\n",
    "\n",
    "debug = True\n",
    "\n",
    "out_dir: Path = Path(\"output\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a58526-f12f-492b-b37c-9748209675a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Level 1C product of Sentinel 2 mission\n",
    "collections = con.list_collections()\n",
    "if backend_url == vito_url or backend_url == vito_dev_url:\n",
    "    collection_id = \"SENTINEL2_L1C_SENTINELHUB\"\n",
    "elif backend_url == openeo_platform_url:\n",
    "    collection_id = \"SENTINEL2_L1C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25390a1e-d844-4dc9-b558-b83259f61869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get reservoirs from database\n",
    "reservoir_dir: Path = out_dir / \"reservoirs\"\n",
    "\n",
    "reservoirs: List[Reservoir] = Reservoir.from_gcp(reservoir_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975f5b26-47b6-4034-988a-cbe357fa0ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_utm_zone(lon: float) -> int:\n",
    "    return math.ceil((180 + lon) / 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f84aa9-5dfd-4fb2-842d-fdca1aaa624e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup AoI and parameters\n",
    "In case of debug, we just take the bounding box of one of the reservoirs in Chzechia that show seasonal variation and extend it so that the reservoirs fit.\n",
    "Otherwise the entirety of Chzechia is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d411677-28ce-4fd7-9a43-d5f32a90aaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug:\n",
    "    geojson_str = \"{\\\"type\\\":\\\"Polygon\\\",\\\"coordinates\\\":[[[16.258372886421807,49.561646293673824],[16.314909857006697,49.561646293673824],[16.314909857006697,49.58980547068479],[16.258372886421807,49.58980547068479],[16.258372886421807,49.561646293673824]]],\\\"geodesic\\\":false}\"\n",
    "    gjson: geojson.Polygon = geojson.loads(geojson_str)\n",
    "    bbox = Polygon(gjson.coordinates[0])\n",
    "else:\n",
    "    # entire chzechia\n",
    "    bbox = Polygon([[12.09,51.06],[12.09, 48.55], [18.87,48.55], [18.87, 51.06], [12.09,51.06]])\n",
    "\n",
    "# convert bbox polygon to utm zone\n",
    "wgs84: CRS = CRS('EPSG:4326')\n",
    "utm_zone: int = get_utm_zone(min(bbox.exterior.xy[0]))\n",
    "utm: CRS = CRS(proj='utm', zone=utm_zone)\n",
    "project_to_utm: Transformer = Transformer.from_crs(wgs84, utm, always_xy=True)\n",
    "project_to_latlon: Transformer = Transformer.from_crs(utm, wgs84, always_xy=True)\n",
    "\n",
    "bbox_utm = transform(project_to_utm.transform, bbox)\n",
    "if debug:\n",
    "    # transform and buffer 1km so all imagery plus buffers is loaded.\n",
    "    bbox_utm = bbox_utm.buffer(1000.)\n",
    "    bbox = transform(project_to_latlon.transform, bbox_utm)\n",
    "\n",
    "band_names = [\"green\", \"nir\", \"swir\", \"cloudmask\", \"cloudp\"]\n",
    "band_codes = [\"B03\", \"B08\", \"B11\", \"CLM\", \"CLP\"]\n",
    "\n",
    "# after crs transform, we get a distorted box, take extremities as bbox\n",
    "xys = bbox_utm.exterior.coords.xy\n",
    "bbox_openeo = {\n",
    "    \"west\": min(xys[0]),\n",
    "    \"east\": max(xys[0]),\n",
    "    \"south\": min(xys[1]),\n",
    "    \"north\": max(xys[1]),\n",
    "    \"crs\": \":\".join(utm.to_authority())\n",
    "}\n",
    "\n",
    "print(f\"openeo spatial extent: {bbox_openeo}\")\n",
    "print(f\"UTM zone: {utm_zone}\")\n",
    "if debug:\n",
    "    start = \"2021-05-01\"\n",
    "    stop = \"2021-08-01\"\n",
    "else:\n",
    "    start = \"2017-04-01\"\n",
    "    stop = \"2021-01-01\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368f155e-eed9-4332-acf2-62a7d1b018fc",
   "metadata": {},
   "source": [
    "## Buffer reservoirs using 300m buffer\n",
    "In order to pickup on flooding / high water levels, we buffer the reservoirs using a 300m buffer. As the AoI needs to be given to the `chunk_polygon` method, we this this locally and not on the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ac73c9-717f-4c92-9d5b-19c3b8cced0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select reservoirs within bbox and buffer 300m\n",
    "from copy import copy\n",
    "\n",
    "def buffer_in_utm(reservoir, buffer_m):\n",
    "    try:\n",
    "        new_res = copy(reservoir)\n",
    "        bounds = new_res.geometry.bounds\n",
    "        min_lon = bounds[0]\n",
    "        _utm_zone: int = get_utm_zone(min_lon)\n",
    "        if abs(_utm_zone - utm_zone) > 1:\n",
    "            # If not close to utm zone, then not in AoI\n",
    "            return None\n",
    "        buffered_geom = transform(project_to_utm.transform, new_res.geometry).buffer(buffer_m, 1)\n",
    "        latlon_geom = transform(project_to_latlon.transform, buffered_geom)\n",
    "        new_res.geometry = latlon_geom\n",
    "    except ValueError as e:\n",
    "        print(reservoir.geometry.wkt)\n",
    "    return new_res\n",
    "    \n",
    "\n",
    "selected = list(\n",
    "    filter(lambda r: bbox.covers(r.geometry),\n",
    "    filter(lambda r: r is not None,\n",
    "    map(lambda r: buffer_in_utm(r, 300.),\n",
    "        reservoirs\n",
    "    )))\n",
    ")\n",
    "selected_mp = MultiPolygon(list(map(lambda s: s.geometry, selected)))\n",
    "selected[0].geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96548d8-eb08-4233-8a75-51457cd8cc81",
   "metadata": {},
   "source": [
    "## Load optical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1f8473-b2e6-473f-92c6-42f7a0e40917",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_optical: DataCube = con.load_collection(\n",
    "        collection_id=collection_id,\n",
    "        spatial_extent=bbox_openeo,\n",
    "        temporal_extent=(start, stop),\n",
    "        bands=band_codes\n",
    "    ).rename_labels(dimension=\"bands\", source=band_codes, target=band_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fa3eac-cc8d-462d-9a7b-08d6173613eb",
   "metadata": {},
   "source": [
    "## Filter optical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79130d52-7a0d-491b-a4a9-fc1844a501b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_udf(path: Path):\n",
    "    with open(path, 'r+') as f:\n",
    "        return f.read()\n",
    "\n",
    "udf_path: Path = Path.cwd().parent / \"udfs\" / \"filter_mostly_clean_images.py\"\n",
    "quality_score_udf = load_udf(udf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d758f18a-1990-4959-a36d-751c8e5427b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry.base import BaseGeometry\n",
    "\n",
    "def filter_mostly_clean_images(\n",
    "    dc: DataCube,\n",
    "    geometry: BaseGeometry,\n",
    "    quality_score_udf: str,\n",
    "    cutoff_percentile: int = 35,\n",
    "    score_percentile: int = 75,\n",
    "    quality_band: str = 'cloudp',\n",
    "    \n",
    ") -> DataCube:\n",
    "    \"\"\"\n",
    "    filters images based on cloud coverage percentile\n",
    "    \"\"\"\n",
    "    process = lambda data: data.run_udf(udf=quality_score_udf, runtime=\"Python\")\n",
    "    return dc.chunk_polygon(chunks=geometry, process=process, context={\n",
    "        \"cutoff_percentile\": cutoff_percentile,\n",
    "        \"quality_band\": quality_band,\n",
    "        \"score_percentile\": score_percentile\n",
    "    })\n",
    "\n",
    "# filtered_dc: DataCube = filter_mostly_clean_images(dc_optical, bbox, quality_score_udf)\n",
    "filtered_dc: DataCube = filter_mostly_clean_images(dc_optical, selected_mp, quality_score_udf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34839469-ec09-4a63-95d2-04701739ba16",
   "metadata": {},
   "source": [
    "## Download filtered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5dcb35-39d5-477f-9dcc-38b3ed91be02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download cube for the fix\n",
    "job = filtered_dc.create_job(\"netcdf\", title=\"get_filtered_data\", description=\"get filtered datacube\")\n",
    "job = job.start_and_wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fa184c-aca8-4fc6-9943-9938e2ea75ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openeo.rest.job import BatchJob\n",
    "\n",
    "job = BatchJob(\"j-41641109c6d14ad2bc4b6ea9bcb00654\", con)\n",
    "filtered_path = out_dir / \"filtered.nc\"\n",
    "job.get_results().get_assets()[0].download(filtered_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a76154-5d07-4c1a-8dcf-8f36df3cb34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray\n",
    "import xarray as xr\n",
    "\n",
    "filtered_path = out_dir / \"filtered.nc\"\n",
    "ds_filtered: xr.Dataset = rioxarray.open_rasterio(filtered_path)\n",
    "ds_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c92617-a335-44c9-aec6-a7a01ecd1a6d",
   "metadata": {},
   "source": [
    "## Visualize filtered DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2b6366-f5e9-4472-b5c7-93904a1eed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "\n",
    "import geoviews as gv\n",
    "import holoviews as hv\n",
    "import numpy as np\n",
    "\n",
    "from holoviews import opts, streams\n",
    "from holoviews.element.tiles import OSM\n",
    "\n",
    "gv.extension(\"bokeh\",\"matplotlib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c36f3d-5693-46fc-a2a9-5adf3783c6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kdims = [\"x\", \"y\", \"t\"]\n",
    "vdims = [\"green\", \"nir\", \"swir\", \"cloudmask\", \"cloudp\"]\n",
    "\n",
    "hv.Dimension.type_formatters[np.datetime64] = '%Y-%m-%d-%H:%M'  # readable time format\n",
    "gv_filtered = gv.Dataset(ds_filtered, kdims=kdims, vdims=vdims, crs=ccrs.UTM(utm_zone)).redim(x=\"lon\", y=\"lat\")\n",
    "print(repr(gv_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4ee70c-5a46-477b-bc28-b852101c3895",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmap = gv_filtered.to(gv.Image, [\"lon\", \"lat\"], \"green\", group=\"filtered\", label=\"filtered\", datatype=[\"xarray\"], dynamic=True)\n",
    "overlay = OSM() * dmap\n",
    "overlay.opts(\n",
    "    opts.Image(cmap=\"turbo\", colorbar=True, clim=(0, 2**12), alpha=0.8, height=500, width=500, tools=[\"hover\"]),\n",
    "    # opts.Image(cmap=\"turbo\", colorbar=True, clim=(0, 100), alpha=0.8, height=500, width=500, tools=[\"hover\"]),\n",
    "    opts.Tiles(height=500, width=500))\n",
    "\n",
    "overlay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96186de-d39b-403d-91d6-0d7f94fc134d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd42fba1-2058-4bba-99c5-fa7201cc1f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_udf(path: Path):\n",
    "    with open(path, 'r+') as f:\n",
    "        return f.read()\n",
    "\n",
    "udf_path: Path = Path.cwd().parent / \"udfs\" / \"preprocess_polygons.py\"\n",
    "preprocess_polygons_udf = load_udf(udf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9770bced-75ed-4a5c-9537-7da27f871155",
   "metadata": {},
   "source": [
    "## Execute Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd42dd74-de6d-46d5-afee-6d30b8420cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openeo.udf import execute_local_udf\n",
    "from openeo.udf.udf_data import UdfData\n",
    "preprocessed: UdfData = execute_local_udf(preprocess_polygons_udf, filtered_path, fmt='netcdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12153244-6b2e-41bb-a501-abd7bb2aa286",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_dcs: List[DataCube] = preprocessed.get_datacube_list()\n",
    "preprocessed_dcs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca967361-7396-4980-af50-d4d835d6db54",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run UDF on backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da691e1-79cc-4520-b8ee-449b0ac63c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_polygons(\n",
    "    dc: DataCube,\n",
    "    geometry: BaseGeometry,\n",
    "    minimum_filled_fraction: int = 0.35,\n",
    "    quality_check_bands: List[str] = [\"green\", \"nir\", \"swir\"]\n",
    "    \n",
    ") -> DataCube:\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    process = lambda data: data.run_udf(udf=preprocess_polygons_udf, runtime=\"Python\")\n",
    "    return dc.chunk_polygon(chunks=geometry, process=process, context={\n",
    "        \"minimum_filled_fraction\": minimum_filled_fraction,\n",
    "        \"quality_check_bands\": quality_check_bands\n",
    "    })\n",
    "\n",
    "preprocessed_dc: DataCube = preprocess_polygons(filtered_dc, selected_mp, quality_score_udf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100f8b1e-7950-4dd9-b178-2913f4fb662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = preprocessed_dc.create_job(\"GTiff\", title=\"quality_score\", description=\"test_quality_score\")\n",
    "job = job.start_and_wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f3d52b-d9ac-4405-b89c-56276a2b9a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openeo.rest.job import BatchJob, JobResults, ResultAsset\n",
    "import re\n",
    "\n",
    "job = BatchJob(\"j-aa1d35202dfb48af88f2f2aafb3903e2\", con)\n",
    "preprocessed_path: Path = out_dir / \"preprocessed\"\n",
    "results: JobResults = job.get_results()\n",
    "assets: List[ResultAsset] = results.get_assets()\n",
    "for asset in assets:\n",
    "    asset.download(preprocessed_path / asset.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0764e7d9-db7e-448d-a988-83c504989c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(assets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a52e136-2919-480c-8abc-388795d4cda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import pandas as pd\n",
    "import rioxarray\n",
    "import re\n",
    "import xarray as xr\n",
    "from typing import Tuple\n",
    "\n",
    "preprocessed_path: Path = out_dir / \"preprocessed\"\n",
    "\n",
    "preprocessed_paths = list(preprocessed_path.glob(\"*.tif\"))\n",
    "preprocessed_dates: List[str] = [re.match(r\".+(\\d{4}-\\d{2}-\\d{2}).+\", path.name).groups()[0] for path in preprocessed_paths]\n",
    "preprocessed_pd: list[Tuple[str, Path]] = [(date(*map(lambda g: int(g), re.match(r\".+(\\d{4})-(\\d{2})-(\\d{2}).+\", path.name).groups())), path) for path in preprocessed_paths]\n",
    "\n",
    "# check same start\n",
    "print(preprocessed_dates[0])\n",
    "print(preprocessed_paths[0])\n",
    "print(preprocessed_pd[0])\n",
    "\n",
    "t: xr.Variable = xr.Variable(\"t\", pd.DatetimeIndex(preprocessed_dates))\n",
    "ds = rioxarray.open_rasterio(preprocessed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a217831-7c85-40c4-8479-ba39a40b8dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dcef3d-929a-4b8c-ae37-5eb1ac4189b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "das = []\n",
    "for d, p in preprocessed_pd:\n",
    "    da = rioxarray.open_rasterio(p)\n",
    "    coords = da.coords\n",
    "    coords.update({\"t\": d})\n",
    "    da = da.assign_coords(coords)\n",
    "    das.append(da)\n",
    "combined: xr.DataArray = xr.concat(das, dim=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afea882d-4c59-4c8a-a916-216d75c4781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds: xr.Dataset = combined.to_dataset('band').rename({1: \"green\", 2: \"nir\", 3: \"swir\", 4: \"cloudmask\", 5: \"cloudp\"})\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f89193b-7131-46e1-9021-6b298f3923df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "\n",
    "import geoviews as gv\n",
    "import holoviews as hv\n",
    "import numpy as np\n",
    "\n",
    "from holoviews import opts, streams\n",
    "from holoviews.element.tiles import OSM\n",
    "\n",
    "gv.extension(\"bokeh\",\"matplotlib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1be16a5-8a77-47ac-b1ae-e425fc6aed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "kdims = [\"x\", \"y\", \"t\"]\n",
    "vdims = [\"green\", \"nir\", \"swir\", \"cloudmask\", \"cloudp\"]\n",
    "\n",
    "hv.Dimension.type_formatters[np.datetime64] = '%Y-%m-%d-%H:%M'  # readable time format\n",
    "gv_preprocessed = gv.Dataset(ds, kdims=kdims, vdims=vdims, crs=ccrs.UTM(utm_zone)).redim(x=\"lon\", y=\"lat\")\n",
    "\n",
    "print(repr(gv_preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7acfa58-d836-4064-9f16-ff73a7879afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmap = gv_preprocessed.to(gv.Image, [\"lon\", \"lat\"], \"green\", group=\"preprocessed_data\", label=\"preprocessed\", datatype=[\"xarray\"], dynamic=True)\n",
    "overlay = OSM() * dmap\n",
    "overlay.opts(\n",
    "    opts.Image(cmap=\"turbo\", colorbar=True, clim=(0, 7000), alpha=0.8, height=500, width=500, tools=[\"hover\"]),\n",
    "    opts.Tiles(height=500, width=500))\n",
    "\n",
    "overlay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da623487-87a4-429d-bf7e-bd83e2757bcd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load water occurrence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a57af88-ea45-44dc-b559-38fab9a28ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.describe_collection(\"GLOBAL_SURFACE_WATER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae739fc3-f942-4500-9d35-d26bd7f58112",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_wo: DataCube = con.load_collection(\n",
    "    collection_id=\"GLOBAL_SURFACE_WATER\",\n",
    "    spatial_extent=bbox_openeo,\n",
    "    bands=[\"occurrence\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10e464b-314d-4eb7-b249-e0bc7686b97f",
   "metadata": {},
   "source": [
    "As the temporal extent works in a weird way with the water occurrence data, either from 1984 until 2019, or until 2020, we have to filter after loading in both date ranges. After of filtering, we want to drop the t-axis. This is because this does not correlate with time the same way as the optical datacube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7430500b-e08b-47cf-a696-964e83ba53cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_wo_latest: DataCube = dc_wo.filter_temporal(extent=(\"2019-12-31\", \"2020-01-02\")).drop_dimension(\"t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6023af8b-bc18-48d3-a1f1-a4eb02e6a2d6",
   "metadata": {},
   "source": [
    "Now we resample spatially onto the optical datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9633efe6-5fe3-4df7-8c68-2df90dfa5108",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_wo_resampled: DataCube = dc_wo_latest.resample_cube_spatial(preprocessed_dc, method=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2699ed-2f9b-458a-8839-02fe74e97bce",
   "metadata": {},
   "source": [
    "## Calculate MNDWI\n",
    "\n",
    "Next step is to calculate the MNDWI of the datacube and merge this cube with the JRC datacube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36103464-96cb-43e8-8a99-e97678a4f14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "green: DataCube = preprocessed_dc.band(\"green\")\n",
    "swir: DataCube = preprocessed_dc.band(\"swir\")\n",
    "mndwi: DataCube = (green - swir) / (green + swir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3eefee-f128-4988-a6d4-81369571456f",
   "metadata": {},
   "source": [
    "Can now be done quicker using built-in openeo support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606146c4-74b6-4f3e-9bd3-408db8cac24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openeo.extra import spectral_indices\n",
    "spectral_indices.list_indices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6ed22b-e157-4b5f-86c1-9e32c5550c96",
   "metadata": {},
   "source": [
    "## Merge Water Occurrence and MNDWI\n",
    "\n",
    "Finally we can merge the two DataCubes: first we need to add a dimension that differs between both cubes if we want to keep both values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2013f3-7d17-4471-bd7f-c5cd5f4e8703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download cube for the fix\n",
    "job = mndwi.create_job(\"netcdf\", title=\"get_timestamps\", description=\"get timestamps for aggregate workaround\")\n",
    "job = job.start_and_wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e32960-18ec-449a-aaeb-c878c3df67ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps_path = out_dir / \"timestamps.nc\"\n",
    "job.get_results().get_assets()[0].download(timestamps_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97377df-fce5-4f80-97bc-fa408fc0b0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray\n",
    "import xarray as xr\n",
    "\n",
    "timestamps_path = out_dir / \"timestamps.nc\"\n",
    "da_timestamps: xr.DataArray = rioxarray.open_rasterio(timestamps_path)\n",
    "da_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbd21e2-0abe-4602-96ab-7f259a3645ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cftime\n",
    "import datetime\n",
    "\n",
    "timestamps = list(map(lambda t: cftime.DatetimeGregorian.strftime(t), da_timestamps[\"t\"].values))\n",
    "timestamps.append(datetime.datetime.now().strftime(\"%Y-%m-%d 00:00:00\")) # add today as aggregate temporal is left-inclusive\n",
    "daterange = [[timestamps[i], timestamps[i+1]] for i in range(len(timestamps) - 1)]\n",
    "daterange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47258931-4a3c-4218-ab1f-ecdd4547c7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openeo import processes\n",
    "\n",
    "mndwi_mergeable = mndwi.add_dimension(name=\"bands\", label=\"MNDWI\", type=\"bands\")\n",
    "# Workaround for https://discuss.eodc.eu/t/merging-datacubes/310/5?u=jaapel\n",
    "mndwi_mergeable = mndwi_mergeable.aggregate_temporal(daterange, reducer=processes.max)\n",
    "mndwi_mergeable.metadata.dimension_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1e6006-6d93-4470-8bb1-f37513389553",
   "metadata": {},
   "source": [
    "Multiply the datacube by 1.0 otherwise we try to merge cubes with different data types (int16 vs float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fa40b1-1b3e-4707-919e-08b8fd2017df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_wo_m: DataCube = dc_wo_resampled.drop_dimension(\"bands\") * 1.0\n",
    "# dc_wo_m = dc_wo_m.add_dimension(name=\"\", label=\"\", type=\"temporal\")\n",
    "dc_wo_m = dc_wo_m.add_dimension(name=\"bands\", label=\"wo\", type=\"bands\")\n",
    "dc_wo_m.metadata.dimension_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7407a5e4-add6-4eb9-b7e4-2f0a5dcf4e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "mndwi_m = mndwi.add_dimension(name=\"bands\", label=\"MNDWI\", type=\"bands\")\n",
    "mndwi_m.metadata.dimension_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5b7c4d-c885-45ff-a24d-6cb7cb89bc47",
   "metadata": {},
   "source": [
    "## Merge DataCube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10baad20-9689-4692-b9dc-67689f721eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openeo import processes\n",
    "\n",
    "# dc_wo_m: DataCube = dc_wo_resampled.add_dimension(\"source\", \"JRC\", type=\"other\")\n",
    "# dc_optical_m: DataCube = dc_optical.add_dimension(\"source\", \"S2_L1C\", type=\"other\")\n",
    "# dc_merged: DataCube = dc_optical_m.merge_cubes(dc_wo_m, overlap_resolver=processes.max)\n",
    "dc_merged: DataCube = mndwi_m.add_dimension(\"bands\", \"MNDWI\", \"bands\").merge_cubes(dc_wo_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824e442c-b2f5-4f94-9bee-22045e3d1261",
   "metadata": {},
   "source": [
    "Download the to-be-merged dc for the water occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4c247c-f70e-44f5-8045-444e583b2e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = dc_wo_m.create_job(\"netcdf\", title=\"dl_merging_wo\", description=\"download water occurrence merge cube\")\n",
    "job = job.start_and_wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0a91f2-a564-4d74-900a-296081db345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_wo_m_path = out_dir / \"m_wo.nc\"\n",
    "job.get_results().get_assets()[0].download(dc_wo_m_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba60839-c4f6-4885-9c44-3d4a086297d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray\n",
    "import xarray as xr\n",
    "\n",
    "dc_wo_m_path = out_dir / \"m_wo.nc\"\n",
    "da_wo_m: xr.Dataset = rioxarray.open_rasterio(dc_wo_m_path)\n",
    "da_wo_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2b26ad-fe50-468f-85c6-def2bf1092ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "\n",
    "import geoviews as gv\n",
    "import holoviews as hv\n",
    "import numpy as np\n",
    "\n",
    "from holoviews import opts, streams\n",
    "from holoviews.element.tiles import OSM\n",
    "\n",
    "gv.extension(\"bokeh\",\"matplotlib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870a565b-a6ec-43bb-a7bb-7434d1bbaf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "kdims = [\"x\", \"y\"]\n",
    "vdims = [\"wo\"]\n",
    "\n",
    "hv.Dimension.type_formatters[np.datetime64] = '%Y-%m-%d-%H:%M'  # readable time format\n",
    "gv_wo_m = gv.Dataset(da_wo_m, kdims=kdims, vdims=vdims, crs=ccrs.UTM(utm_zone)).redim(x=\"lon\", y=\"lat\")\n",
    "print(repr(gv_wo_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd308d6-8596-4387-b524-6f587d1f251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmap = gv_wo_m.to(gv.Image, [\"lon\", \"lat\"], \"wo\", group=\"mergeable_wo\", label=\"mergeable_wo\", datatype=[\"xarray\"])\n",
    "overlay = OSM() * dmap\n",
    "overlay.opts(\n",
    "    opts.Image(cmap=\"turbo\", colorbar=True, clim=(0, 100), alpha=0.8, height=500, width=500, tools=[\"hover\"]),\n",
    "    # opts.Image(cmap=\"turbo\", colorbar=True, clim=(0, 100), alpha=0.8, height=500, width=500, tools=[\"hover\"]),\n",
    "    opts.Tiles(height=500, width=500))\n",
    "\n",
    "overlay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1034c669-121a-471d-a931-7d9fe2343dd8",
   "metadata": {},
   "source": [
    "Downloading the mndwi cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cd3afe-b8ac-485f-845f-18b91104428e",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = mndwi_mergeable.create_job(\"netcdf\", title=\"mndwi_merging\", description=\"download mndwi merge cube\")\n",
    "job = job.start_and_wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1c039e-dcd8-4f31-ac7f-b7eaef1bf13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_mndwi_path = out_dir / \"mergeable_mndwi.nc\"\n",
    "job.get_results().get_assets()[0].download(merge_mndwi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f92f5d1-2ccb-433a-920c-56ded55631e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray\n",
    "import xarray as xr\n",
    "\n",
    "merge_mndwi_path = out_dir / \"mergeable_mndwi.nc\"\n",
    "da_merged_mndwi: xr.DataArray = rioxarray.open_rasterio(merge_mndwi_path)\n",
    "da_merged_mndwi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a68928-2435-4291-aa1d-f37b50b92376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "\n",
    "import geoviews as gv\n",
    "import holoviews as hv\n",
    "import numpy as np\n",
    "\n",
    "from holoviews import opts, streams\n",
    "from holoviews.element.tiles import OSM\n",
    "\n",
    "gv.extension(\"bokeh\",\"matplotlib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1899bf11-12c1-4f5a-b385-b578f83237a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kdims = [\"x\", \"y\", \"t\"]\n",
    "vdims = [\"MNDWI\"]\n",
    "\n",
    "hv.Dimension.type_formatters[np.datetime64] = '%Y-%m-%d-%H:%M'  # readable time format\n",
    "gv_mndwi_m = gv.Dataset(da_merged_mndwi, kdims=kdims, vdims=vdims, crs=ccrs.UTM(utm_zone)).redim(x=\"lon\", y=\"lat\")\n",
    "print(repr(gv_mndwi_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a69bf06-c407-4835-9858-d62da7277778",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmap = gv_mndwi_m.to(gv.Image, [\"lon\", \"lat\"], \"MNDWI\", group=\"mergeable_mndwi\", label=\"mergeable_mndwi\", datatype=[\"xarray\"], dynamic=True)\n",
    "overlay = OSM() * dmap\n",
    "overlay.opts(\n",
    "    opts.Image(cmap=\"turbo\", colorbar=True, clim=(-1, 1), alpha=0.8, height=500, width=500, tools=[\"hover\"]),\n",
    "    # opts.Image(cmap=\"turbo\", colorbar=True, clim=(0, 100), alpha=0.8, height=500, width=500, tools=[\"hover\"]),\n",
    "    opts.Tiles(height=500, width=500))\n",
    "\n",
    "overlay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bc6a6c-f78e-4e63-b1c4-a463720f1bcf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Download and inspect result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5ff66d-65d6-4c4e-bc11-9362d46b0031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openeo.rest.job import RESTJob\n",
    "job: RESTJob = dc_merged.create_job(\"netcdf\", title=\"merging_wo\", description=\"merging water occurrence.\")\n",
    "job = job.start_and_wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342bb921-33a1-401a-83c7-f159ec7fd9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_path = out_dir / \"merged.nc\"\n",
    "job.get_results().get_assets()[0].download(merged_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d76d0b-d5c7-4d48-9973-7455483e9a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray\n",
    "import xarray as xr\n",
    "\n",
    "merged_path = out_dir / \"merged.nc\"\n",
    "fixed_merged_path: Path = out_dir / \"merged_fixed.nc\"\n",
    "ds_merged: xr.Dataset = rioxarray.open_rasterio(merged_path)\n",
    "ds_merged = ds_merged.drop(\"crs\")\n",
    "ds_merged.to_netcdf(fixed_merged_path)\n",
    "ds_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd34566-e68b-445b-82d9-f400917eae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "\n",
    "import geoviews as gv\n",
    "import holoviews as hv\n",
    "import numpy as np\n",
    "\n",
    "from holoviews import opts, streams\n",
    "from holoviews.element.tiles import OSM\n",
    "\n",
    "gv.extension(\"bokeh\",\"matplotlib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c7ca57-d763-41ee-a0e1-41d4286fd91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kdims = [\"x\", \"y\", \"t\"]\n",
    "vdims = [\"wo\", \"MNDWI\"]\n",
    "\n",
    "hv.Dimension.type_formatters[np.datetime64] = '%Y-%m-%d-%H:%M'  # readable time format\n",
    "gv_merged = gv.Dataset(ds_merged, kdims=kdims, vdims=vdims, crs=ccrs.UTM(utm_zone)).redim(x=\"lon\", y=\"lat\")\n",
    "# gv_merged = gv.Dataset(da_merged, kdims=kdims, vdims=vdims).redim(x=\"lon\", y=\"lat\")\n",
    "print(repr(gv_merged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da69fe50-1d23-4040-b7f9-f90785490585",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmap = gv_merged.to(gv.Image, [\"lon\", \"lat\"], \"wo\", group=\"raw_data\", label=\"raw\", datatype=[\"xarray\"], dynamic=True)\n",
    "overlay = OSM() * dmap\n",
    "overlay.opts(\n",
    "    # opts.Image(cmap=\"turbo\", colorbar=True, clim=(0, 100), alpha=0.8, height=500, width=500, tools=[\"hover\"]),\n",
    "    opts.Image(cmap=\"turbo\", colorbar=True, clim=(-1, 1), alpha=0.8, height=500, width=500, tools=[\"hover\"]),\n",
    "    opts.Tiles(height=500, width=500))\n",
    "\n",
    "overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee11a4f7-cec4-480c-be86-b77a22284472",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
